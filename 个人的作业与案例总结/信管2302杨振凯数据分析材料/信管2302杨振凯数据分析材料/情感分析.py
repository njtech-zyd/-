import requests
import json
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# -------------------------- ã€å…³é”®é€‚é…ï¼šä½ çš„è±†ç“£è¯„è®ºæ–‡ä»¶å‚æ•°ã€‘--------------------------
API_KEY = "sk-5a102bf40b204935afdf202dd12f7658"  # æ›¿æ¢ä¸ºä½ çš„ DeepSeek API Key
INPUT_FILE = "E:\å¤§å­¦å¥‡å¥‡æ€ªæ€ªçš„ä½œä¸š\å®éªŒ\douban_FINAL_CLEANED.csv"  # ä½ çš„è±†ç“£è¯„è®ºæ–‡ä»¶è·¯å¾„ï¼ˆå›ºå®šï¼‰
OUTPUT_FILE = "E:\å¤§å­¦å¥‡å¥‡æ€ªæ€ªçš„ä½œä¸š\å®éªŒ\douban_comments_sentiment_result.csv"  # è¾“å‡ºç»“æœè·¯å¾„ï¼ˆä¿å­˜åœ¨åŒç›®å½•ï¼‰
COMMENT_COLUMN = "comment"  # ä½ çš„è¯„è®ºåˆ—åï¼ˆå·²ç¡®è®¤æ˜¯ commentï¼‰
BATCH_SIZE = 500  # 1 æ‰¹å³å¯å¤„ç†å®Œ 461 æ¡æ•°æ®ï¼ˆå…è´¹é¢åº¦è¶³å¤Ÿï¼‰
MAX_WORKERS = 10  # å¹¶å‘çº¿ç¨‹æ•°ï¼ˆå¹³è¡¡æ•ˆç‡å’Œé™æµï¼‰
RETRY_TIMES = 3  # å¤±è´¥è‡ªåŠ¨é‡è¯•æ¬¡æ•°
MODEL = "deepseek-chat"  # ç¨³å®šçš„é€šç”¨å¯¹è¯æ¨¡å‹
TEXT_MAX_LENGTH = 10000  # æˆªæ–­è¶…é•¿æ–‡æœ¬ï¼ˆé¿å… API æŠ¥é”™ï¼‰

# -------------------------- ã€å·¥å…·å‡½æ•°ï¼šæ— éœ€ä¿®æ”¹ã€‘--------------------------
# 1. è¯»å–è±†ç“£è¯„è®ºæ•°æ®ï¼ˆä¿ç•™æ‰€æœ‰åŸå§‹åˆ—ï¼šusernameã€ratingã€time ç­‰ï¼‰
def load_comments(file_path):
    df = pd.read_csv(file_path, encoding="utf-8-sig")
    # æ•°æ®é¢„å¤„ç†ï¼šå»é‡ï¼ˆé¿å…é‡å¤è¯„è®ºï¼‰ã€æˆªæ–­è¶…é•¿æ–‡æœ¬ã€ä¿ç•™æ‰€æœ‰åŸå§‹åˆ—
    df = df.drop_duplicates(subset=[COMMENT_COLUMN])  # æŒ‰è¯„è®ºå»é‡
    df[COMMENT_COLUMN] = df[COMMENT_COLUMN].astype(str).str[:TEXT_MAX_LENGTH]  # æˆªæ–­
    df = df.reset_index(drop=True)
    print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è±†ç“£æœ‰æ•ˆè¯„è®ºï¼ˆåŸå§‹æ•°æ® 461 æ¡ï¼Œå»é‡åå‰©ä½™ï¼‰")
    print(f"ğŸ“Š åŸå§‹åˆ—ï¼š{df.columns.tolist()}ï¼ˆå°†ä¿ç•™æ‰€æœ‰åˆ—ï¼Œæ–°å¢æƒ…æ„Ÿåˆ†æç»“æœåˆ—ï¼‰")
    return df

# 2. å•æ¡è¯„è®ºæƒ…æ„Ÿåˆ†æï¼ˆå¸¦åŸç”Ÿé‡è¯•ï¼Œé¿å…ä¾èµ– tenacityï¼‰
def analyze_single_comment(comment):
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    # ç²¾å‡†æç¤ºè¯ï¼ˆé€‚é…å¤šè¯­è¨€ï¼Œç¡®ä¿è¾“å‡ºæ ¼å¼ç»Ÿä¸€ï¼‰
    prompt = f"""
    å¯¹ä»¥ä¸‹è±†ç“£è¯„è®ºåšæƒ…æ„Ÿåˆ†æï¼Œä¸¥æ ¼éµå®ˆï¼š
    1. æƒ…æ„Ÿæ ‡ç­¾ä»…è¿”å› positiveï¼ˆæ­£é¢ï¼‰ã€negativeï¼ˆè´Ÿé¢ï¼‰ã€neutralï¼ˆä¸­æ€§ï¼‰ï¼›
    2. ç½®ä¿¡åº¦ä¿ç•™ 4 ä½å°æ•°ï¼ˆ0~1ï¼Œè¶Šæ¥è¿‘ 1 è¶Šå¯ä¿¡ï¼‰ï¼›
    3. è¯­è¨€è¯†åˆ«è¿”å›ç¼©å†™ï¼ˆå¦‚ zh=ä¸­æ–‡ã€en=è‹±æ–‡ï¼‰ï¼›
    4. ä»…è¾“å‡º JSON å­—ç¬¦ä¸²ï¼Œæ— é¢å¤–æ–‡å­—ï¼Œå­—æ®µï¼šsentimentã€confidenceã€languageã€‚
    
    è¯„è®ºå†…å®¹ï¼š{comment}
    """
    data = {
        "model": MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.0  # é›¶éšæœºæ€§ï¼Œç»“æœç¨³å®š
    }
    # åŸç”Ÿé‡è¯•é€»è¾‘
    retry_intervals = [1, 2, 4]
    for attempt in range(RETRY_TIMES):
        try:
            time.sleep(0.1)  # é™ä½é™æµé£é™©
            response = requests.post(
                url="https://api.deepseek.com/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=15
            )
            response.raise_for_status()
            model_res = response.json()
            result_json = model_res["choices"][0]["message"]["content"].strip()
            return json.loads(result_json)
        except Exception as e:
            if attempt == RETRY_TIMES - 1:
                raise e
            time.sleep(retry_intervals[attempt])

# 3. æ‰¹é‡å¤„ç†ï¼ˆä¿ç•™åŸå§‹åˆ—ï¼Œæ–°å¢æƒ…æ„Ÿç»“æœï¼ŒåŸç”Ÿè¿›åº¦æç¤ºï¼‰
def batch_analyze_comments(df):
    all_results = []
    total = len(df)
    print(f"\n===== å¼€å§‹æ‰¹é‡åˆ†æ {total} æ¡è±†ç“£è¯„è®º =====")
    
    # å¤šçº¿ç¨‹å¤„ç†
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_idx = {
            executor.submit(analyze_single_comment, row[COMMENT_COLUMN]): row 
            for _, row in df.iterrows()  # ä¿ç•™æ¯è¡ŒåŸå§‹æ•°æ®ï¼ˆusernameã€rating ç­‰ï¼‰
        }
        processed_count = 0
        for future in as_completed(future_to_idx):
            processed_count += 1
            # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯ 20 æ¡æ›´æ–°ä¸€æ¬¡ï¼‰
            if processed_count % 20 == 0 or processed_count == total:
                print(f"è¿›åº¦ï¼š{processed_count}/{total} [{(processed_count/total)*100:.1f}%]")
            
            row = future_to_idx[future]
            try:
                sentiment_res = future.result()
                # åˆå¹¶åŸå§‹æ•°æ®å’Œæƒ…æ„Ÿç»“æœ
                result_row = row.to_dict()  # åŸå§‹åˆ—ï¼ˆusernameã€rating ç­‰ï¼‰
                result_row.update({
                    "æƒ…æ„Ÿæ ‡ç­¾": sentiment_res["sentiment"],
                    "æƒ…æ„Ÿç½®ä¿¡åº¦": sentiment_res["confidence"],
                    "æ–‡æœ¬è¯­è¨€": sentiment_res["language"],
                    "åˆ†æçŠ¶æ€": "æˆåŠŸ"
                })
            except Exception as e:
                result_row = row.to_dict()
                result_row.update({
                    "æƒ…æ„Ÿæ ‡ç­¾": None,
                    "æƒ…æ„Ÿç½®ä¿¡åº¦": None,
                    "æ–‡æœ¬è¯­è¨€": None,
                    "åˆ†æçŠ¶æ€": f"å¤±è´¥ï¼š{str(e)[:40]}"
                })
            all_results.append(result_row)
    
    # ä¿å­˜ç»“æœï¼ˆåŒ…å«æ‰€æœ‰åŸå§‹åˆ— + æƒ…æ„Ÿåˆ†æåˆ—ï¼‰
    result_df = pd.DataFrame(all_results)
    result_df.to_csv(OUTPUT_FILE, index=False, encoding="utf-8-sig")
    return result_df

# -------------------------- ã€æ‰§è¡Œå…¥å£ï¼šç›´æ¥è¿è¡Œã€‘--------------------------
if __name__ == "__main__":
    try:
        # 1. åŠ è½½æ•°æ®
        comments_df = load_comments(INPUT_FILE)
        
        # 2. æ‰¹é‡åˆ†æ
        result_df = batch_analyze_comments(comments_df)
        
        # 3. è¾“å‡ºåˆ†ææŠ¥å‘Š
        print("\n===== è±†ç“£è¯„è®ºæƒ…æ„Ÿåˆ†æå®Œæˆï¼=====")
        success_df = result_df[result_df["åˆ†æçŠ¶æ€"] == "æˆåŠŸ"]
        fail_df = result_df[result_df["åˆ†æçŠ¶æ€"] != "æˆåŠŸ"]
        
        print(f"ğŸ“Š æ•´ä½“ç»Ÿè®¡ï¼š")
        print(f"   - æ€»è¯„è®ºæ•°ï¼š{len(result_df)}")
        print(f"   - æˆåŠŸåˆ†æï¼š{len(success_df)} æ¡ï¼ˆ{len(success_df)/len(result_df)*100:.1f}%ï¼‰")
        print(f"   - å¤±è´¥åˆ†æï¼š{len(fail_df)} æ¡")
        
        if len(success_df) > 0:
            print(f"\nâ¤ï¸  æƒ…æ„Ÿåˆ†å¸ƒï¼š")
            sentiment_count = success_df["æƒ…æ„Ÿæ ‡ç­¾"].value_counts()
            for sent, count in sentiment_count.items():
                sent_cn = {"positive": "æ­£é¢", "negative": "è´Ÿé¢", "neutral": "ä¸­æ€§"}[sent]
                print(f"   - {sent_cn}è¯„è®ºï¼š{count} æ¡ï¼ˆ{count/len(success_df)*100:.1f}%ï¼‰")
        
        print(f"\nğŸ’¾ ç»“æœæ–‡ä»¶å·²ä¿å­˜è‡³ï¼š{OUTPUT_FILE}")
        print(f"   åŒ…å«åˆ—ï¼š{result_df.columns.tolist()}")
        print("\nğŸ” ç»“æœé¢„è§ˆï¼ˆå‰ 2 è¡Œï¼‰ï¼š")
        print(result_df[["username", "rating", "comment", "æƒ…æ„Ÿæ ‡ç­¾", "æƒ…æ„Ÿç½®ä¿¡åº¦"]].head(2))
    
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸ï¼š{str(e)}")
        if "API_KEY" in str(e) or "401" in str(e):
            print("   æç¤ºï¼šè¯·æ£€æŸ¥ API Key æ˜¯å¦æœ‰æ•ˆï¼ˆå» DeepSeek æ§åˆ¶å°é‡æ–°ç”Ÿæˆï¼‰")